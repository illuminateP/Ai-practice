{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# endterm.ppx 76p "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_data와 y_data 준비\n",
    "# x_data와 y_data는 이미 준비되어 있다고 가정합니다\n",
    "# x_data = ...\n",
    "# y_data = ...\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 넘파이 패키지\n",
    "import pandas as pd  # 판다스 패키지\n",
    "import matplotlib.pyplot as plt         # 그래프 패키지\n",
    "from sklearn.model_selection import train_test_split      # 데이터 셋 분할\n",
    "\n",
    "from sklearn.linear_model import LinearRegression    # 선형 회귀 패키지\n",
    "from sklearn.linear_model import Ridge        # 릿지 선형 회귀 패키지\n",
    "from sklearn.preprocessing import PolynomialFeatures  # 특성 변환기 패키지\n",
    "\n",
    "import tensorflow as tf                                               # 인공지능 패키지\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # 넘파이 패키지\n",
    "import pandas as pd                                    # 판다스 패키지\n",
    "import matplotlib.pyplot as plt                        # 그래프 패키지\n",
    "\n",
    "from sklearn.linear_model import LinearRegression      # 선형 회귀 패키지\n",
    "from sklearn.linear_model import Ridge                 # 릿지 선형 회귀 패키지\n",
    "from sklearn.preprocessing import PolynomialFeatures   # 특성 변환기 패키지\n",
    "\n",
    "import tensorflow as tf                                # 인공지능 패키지\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.layers import Dense, Input, Concatenate, LSTM, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error        # 평균 절대값 에러(모델 평가 지수)\n",
    "from sklearn.metrics import mean_squared_error         # 평균 제곱근 에러(모델 평가 지수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩과 구굴 드라이브 연동\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')   # content는 내 드라이브 디렉토리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/week12/mokpo_data.csv')\n",
    "print(data.info())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)          # 데이터 프레임을 배열로 변환\n",
    "# 정규화 : 각 열 단위로 0 부터 1롤 변환\n",
    "data = (data - np.min(data, 0)) / (np.max(data, 0) - np.min(data, 0))\n",
    "print(data.shape)              # 데이터 스케일 보기\n",
    "print(data[0 : 5])             #\n",
    "print(len(data) * 0.8)         # 데이터 나누기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 만들기(주의 : 다음 시간 예측입니다)\n",
    "x_data = [] # 입력데이터 리스트\n",
    "y_data = [] # 출력데이터 리스트\n",
    "\n",
    "for i in range(0, len(data_poly) - 24) :   \n",
    "    x = data_poly[i : i + 24, : ]\n",
    "    y = data_poly[i + 24, [-1]]\n",
    "    x_data.append(x)\n",
    "    y_data.append(y)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 만들기 8 :2\n",
    "\n",
    "수치 print(len(data) * 0.8) 으로 수정 필요\n",
    "\n",
    "x_train = x_data[ : 24499 ,  : ]         # 학습 데이터\n",
    "y_train = y_data[ : 24499]\n",
    "\n",
    "x_test = x_data[24499 : ,  : ]          # 테스트 데이터\n",
    "y_test = y_data[24499 :]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 특성 늘리기 degree = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? 왜 삭제해\n",
    "x_data = data[ : , : ]             # 입력 데이터(마지막 샘플 전까지) 삭제해야함\n",
    "y_data = data[ : , -1]            # 타겟 데이터(다음날 부터 마지막 샘플까지) 삭제해야함\n",
    "\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "poly = PolynomialFeatures(degree=4, include_bias=False) # 특성 변환기 모델\n",
    "poly.fit(x_data)             # 특성을 늘리는 학습\n",
    "\n",
    "data_poly = poly.transform(x_data)      # 여기서 훈련 셋 특성 변함\n",
    "print(data_poly.shape)           # 특성 변환 스케일\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()                              # 선형 회귀 모델\n",
    "lr.fit(train_poly, y_train)                    # 모델 훈련\n",
    "print(lr.score(train_poly, y_train))           # 훈련 셋 평가\n",
    "print(lr.score(test_poly, y_test))             # 테스트 셋 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인공신경망 다중회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(494,))                               # 입력층\n",
    "hidden1 = Dense(256, activation='relu')(input)          # 1 층\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)        # 2 층\n",
    "hidden3 = Dense(256, activation='relu')(hidden2)        # 3 층\n",
    "hidden4 = Dense(256, activation='relu')(hidden3)        # 4층\n",
    "hidden5 = Dense(256, activation='relu')(hidden4)        # 5층\n",
    "hidden6 = Dense(256, activation='relu')(hidden5)        # 6층\n",
    "output = Dense(1, activation='linear')(hidden6)      # 출력 층\n",
    "\n",
    "model_DNN = Model(input, output)      # 모델 구축\n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습과정 설정하기\n",
    "model_DNN.compile(loss = 'mse', optimizer = optimizers.Adam(0.001), metrics=['accuracy'])\n",
    "monitor_val_lose = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "hist = model_DNN.fit(\n",
    "train_poly, y_train,                               # 입력 / 라벨\n",
    "epochs = 20, batch_size = 10,                   # 학습 회수 / 10개 샘플마다 학습\n",
    "validation_data=(test_poly, y_test),               # 검증 데이터\n",
    "callbacks = [monitor_val_lose]  # 저장 및 모니터링\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_DNN.predict(test_poly)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predict)\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "rmse = mse**0.5\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 병렬 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate                    # 두 출력을 연결\n",
    "\n",
    "inputA = Input(shape=(494,))                            # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(input)          # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)        # 2 층\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)        # 3 층\n",
    "outputA = Dense(16, activation='linear')(hidden6)       # 출력 층\n",
    "\n",
    "inputB = Input(shape=(494,))                            # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(input)          # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)        # 2 층\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)        # 3 층\n",
    "outputB = Dense(16, activation='linear')(hidden6)       # 출력 층\n",
    "\n",
    "# 두개의 인공 신경망의 출력을 연결(concatenate)\n",
    "result = concatenate([inputA, inputB])\n",
    "\n",
    "z = Dense(8, activation = \"relu\")(result)\n",
    "\n",
    "z = Dense(1, activation = \"linear\")(z)\n",
    "model_DNN = Model(inputs = [inputA, inputB], outputs = z)\n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습과정 설정하기\n",
    "model_DNN.compile(loss = 'mse', optimizer = optimizers.SGD(0.001), metrics=['accuracy'])\n",
    "\n",
    "monitor_val_lose = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "hist = model_DNN.fit(\n",
    "                    [train_poly, train_poly], y_train,                               # 입력 / 라벨\n",
    "                     epochs = 20, batch_size = 10,                   # 학습 회수 / 10개 샘플마다 학습\n",
    "                     validation_data=([test_poly, test_poly], y_test),               # 검증 데이터\n",
    "                     callbacks = [monitor_val_lose]  # 저장 및 모니터링\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_DNN.predict([test_poly, test_poly])\n",
    "\n",
    "mae = mean_absolute_error(y_test, predict)\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "rmse = mse**0.5\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[ : -1, : ]             # 입력 데이터(마지막 샘플 전까지)\n",
    "y_data = data[1 : , -1]              # 타겟 데이터(다음날 부터 마지막 샘플까지)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)   # 특성 변환기 모델\n",
    "poly.fit(x_data)                                          # 3개의 특성을 이용하여 특성을 늘리는 학습\n",
    "\n",
    "data_poly = poly.transform(x_data)                        # 여기서 훈련 셋 특성 변함\n",
    "\n",
    "print(data_poly.shape)                                    # 특성 변환 스케알"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []                         # 입력데이터 리스트\n",
    "y_data = []                         # 출력데이터 리스트\n",
    "\n",
    "for i in range(1, len(data_poly) - 24) :\n",
    "  x = data_poly[i : i + 24, : ]\n",
    "  y = data_poly[i + 24, [-1]]\n",
    "  x_data.append(x)\n",
    "  y_data.append(y)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 만들기\n",
    "x_train = x_data[ : 24499 ,  : ]         # 학습 데이터\n",
    "y_train = y_data[ : 24499]\n",
    "\n",
    "x_test = x_data[24499 : ,  : ]          # 테스트 데이터\n",
    "y_test = y_data[24499 :]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(24, 494))\n",
    "lstm_layer = LSTM(128)(inputs)\n",
    "hidden1 = Dense(128, activation='relu')(lstm_layer)\n",
    "outputs = Dense(1, activation='linear')(hidden1)\n",
    "model_LSTM = Model(inputs = inputs, outputs = outputs)\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 하기\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
    "model_LSTM.compile(loss = 'mse', optimizer = optimizers.Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_LSTM.fit(\n",
    "                  x_train, y_train,\n",
    "                  epochs = 20, batch_size = 10,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks = [early_stopping]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_LSTM.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predict)\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "rmse = mse**0.5\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(24, 494))\n",
    "lstm_layer = Bidirectional(LSTM(128))(inputs)\n",
    "hidden1 = Dense(128, activation='relu')(lstm_layer)\n",
    "outputs = Dense(1, activation='linear')(hidden1)\n",
    "model_BiLSTM = Model(inputs = inputs, outputs = outputs)\n",
    "model_BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 하기\n",
    "model_checkpoint = ModelCheckpoint(filepath =  \"./model/LSTM.h5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3)\n",
    "\n",
    "# 모델 학습과정 설정하기\n",
    "model_BiLSTM.compile(loss = 'mse', optimizer = optimizers.Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_BiLSTM.fit(\n",
    "                  x_train, y_train,\n",
    "                  epochs = 20, batch_size = 10,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  callbacks = [model_checkpoint, early_stopping]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model_BiLSTM.predict(x_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, predict)\n",
    "mse = mean_squared_error(y_test, predict)\n",
    "rmse = mse**0.5\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고 ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 지수\n",
    "## 코딩 #########################################\n",
    "\n",
    "# 최초 학습은 위 행에서 진행했기에 , rsme 만 출력\n",
    "\n",
    "# 테스트 셋 예측값\n",
    "test_prediction = lr.predict(test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_prediction)\n",
    "rmse = mse**0.5\n",
    "print(f\"MSE for 1th attempt : {mse}\")\n",
    "print(f\"MSE for 1th attempt : {rmse} \\n\")\n",
    "\n",
    "# 모델 4번 재훈련 후 rmse 출력\n",
    "for i in range(1,5):\n",
    "  # 모델 훈련\n",
    "  lr.fit(train_poly ,y_train)\n",
    "  # 테스트 셋 예측값\n",
    "  test_prediction = lr.predict(test_poly)\n",
    "  # 모델 평가 지수(MSE, RMSE)\n",
    "\n",
    "  mse = mean_squared_error(y_test, test_prediction)\n",
    "  rmse = mse**0.5\n",
    "\n",
    "  print(f\"MSE for {i+1}th attempt : {mse}\")\n",
    "  print(f\"RMSE for {i+1}th attempt : {rmse} \\n\")\n",
    "  ## 코딩 #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 지수\n",
    "## 코딩 #########################################\n",
    "\n",
    "# 모델 5번 재훈련 후 rmse 출력\n",
    "for i in range(5):\n",
    "  # rmse 값이 목적이므로 hist로 저장 , 콜백하지 않았습니다.\n",
    "  # 모델 1회 훈련\n",
    "  model.fit(x_train, y_train)\n",
    "\n",
    "  # 테스트 셋 예측값\n",
    "  test_prediction = model.predict(x_test)\n",
    "\n",
    "  # 모델 평가 지수(MSE, RMSE)\n",
    "  mse = mean_squared_error(y_test, test_prediction)\n",
    "  rmse = mse**0.5\n",
    "\n",
    "  print(\"\")\n",
    "  print(f\"MSE for {i+1}th attempt : {mse}\")\n",
    "  print(f\"RMSE for {i+1}th attempt : {rmse} \\n\")\n",
    "  ## 코딩 #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ★ 모델 학습\n",
    "hist = model_DNN.fit(\n",
    "                    # ★ 입력이 2개 , 출력도 2개? -> DNN 2개를 병렬연결했기 때문\n",
    "                    [train_poly, train_poly], y_train,                               # 입력 / 라벨\n",
    "                     epochs = 20, batch_size = 10,                   # 학습 회수 / 10개 샘플마다 학습\n",
    "                     validation_data=([test_poly, test_poly], y_test),               # 검증 데이터\n",
    "                     callbacks = [monitor_val_lose]  # 저장 및 모니터링\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate                    # 두 출력을 연결\n",
    "\n",
    "# 모델 A\n",
    "inputA = Input(shape=(494,))                            # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(inputA)          # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)        # 2 층\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)        # 3 층\n",
    "outputA = Dense(8, activation='linear')(hidden3)       # 출력 층\n",
    "#\n",
    "\n",
    "## 모델 B\n",
    "inputB = Input(shape=(494,))                            # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(inputB)          # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)        # 2 층\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)        # 3 층\n",
    "outputB = Dense(16, activation='linear')(hidden3)       # 출력 층\n",
    "##\n",
    "\n",
    "# 두개의 인공 신경망(DNN)의 출력을 연결(concatenate)\n",
    "# output A 와 output B를 연결해 총 노드 수가 8 + 8 = 16개\n",
    "result = concatenate([outputA, outputB])\n",
    "\n",
    "z = Dense(8, activation = \"relu\")(result)\n",
    "\n",
    "z = Dense(1, activation = \"linear\")(z)\n",
    "\n",
    "# 두 모델을 합쳐 만들어진 모델\n",
    "model_DNN = Model(inputs = [inputA, inputB], outputs = z)\n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate                  # 두 출력을 연결\n",
    "# modelA ######################################################\n",
    "inputA = Input(shape=(494,))                             # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(inputA)    # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)  # 2 층\n",
    "outputA = Dense(8, activation='linear')(hidden2)   # 출력 층\n",
    "\n",
    "# modelB #######################################################\n",
    "inputB = Input(shape=(494,))                             # 입력층\n",
    "hidden1 = Dense(128, activation='relu')(inputB)    # 1 층\n",
    "hidden2 = Dense(128, activation='relu')(hidden1)  # 2 층\n",
    "hidden3 = Dense(128, activation='relu')(hidden2)  # 3 층\n",
    "hidden4 = Dense(256, activation='relu')(hidden3)  # 4층\n",
    "hidden5 = Dense(256, activation='relu')(hidden4)  # 5층\n",
    "hidden6 = Dense(256, activation='relu')(hidden5)  # 6층\n",
    "outputB = Dense(8, activation='linear')(hidden6)   # 출력 층\n",
    "\n",
    "# 두개의 DNN 출력을 연결(concatenate) ##########################\n",
    "result = concatenate([outputA, outputB])            # 8 + 8 = 16\n",
    "z = Dense(8, activation = \"relu\")(result)\n",
    "z = Dense(1, activation = \"linear\")(z)\n",
    "\n",
    "model_DNN = Model(inputs = [inputA, inputB], outputs = z)\n",
    "model_DNN.summary() \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
